{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8564181-6b5a-46bb-a390-bc72cac08a40",
   "metadata": {},
   "source": [
    "# Comparing_Models_KNN_Feature_Selection._Embedded_Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11be3a-c7d7-4034-ba06-dbe2ea76a47a",
   "metadata": {},
   "source": [
    "1. Fit the models  `LinearRegression`,`Lasso` and `Ridge` and compare the model performances. \n",
    "2. Define a function that takes a list of models and trains (and tests) them so we can try a lot of them without repeating code.\n",
    "3. Use feature selection techniques (P-Value, RFE) to select a subset of features to train the model with (if necessary).\n",
    "4. (optional) Re-fit the models with the selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e83fc8-06c5-48d0-998e-ec82c1055aed",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "441bcd04-7788-4c1e-aee2-50a0644a0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae\n",
    "from sklearn.feature_selection import VarianceThreshold # It only works with numerical features\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f273a5-61aa-4c51-979f-6e2b58892ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'marketing_customer_analysis_clean.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01924c6e-f16d-4083-b5b6-a7a0e618394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['unnamed:_0', 'customer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5339acb4-4129-42a7-acf3-d0c52057b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the columns\n",
    "categoricals_df = df.select_dtypes(include='object')\n",
    "numericals_df = df.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f38079-0e15-42a3-89ff-e6b3587500d2",
   "metadata": {},
   "source": [
    "## Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfcb15c-08e8-45a6-9e95-3e374b952458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Dataframes splitt in nominal and ordinal\n",
    "nominal_columns = ['state', 'response', 'employmentstatus', 'gender', \n",
    "                   'location_code', 'marital_status', 'policy_type', \n",
    "                   'sales_channel', 'policy','vehicle_class', 'vehicle_type', 'renew_offer_type']\n",
    "nominal_df = categoricals_df[nominal_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd5d041-40cd-4812-9750-30247f0e06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Dataframes splitt in nominal and ordinal\n",
    "ordinal_columns = ['coverage','education', 'vehicle_size']\n",
    "ordinal_df = categoricals_df[ordinal_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8479433-28ab-4974-b4cb-0047ab42a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies with all the norminal columns\n",
    "con_norminals_df = pd.get_dummies(nominal_df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbac0e03-78c3-4fcf-a099-45f352dfd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vonke\\AppData\\Local\\Temp\\ipykernel_8268\\2652735968.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordinal_df['coverage'] = enc.fit_transform(ordinal_df[['coverage']])\n",
      "C:\\Users\\vonke\\AppData\\Local\\Temp\\ipykernel_8268\\2652735968.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordinal_df['education'] = enc.fit_transform(ordinal_df[['education']])\n",
      "C:\\Users\\vonke\\AppData\\Local\\Temp\\ipykernel_8268\\2652735968.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ordinal_df['vehicle_size'] = enc.fit_transform(ordinal_df[['vehicle_size']])\n"
     ]
    }
   ],
   "source": [
    "# For 'coverage' column\n",
    "enc = OrdinalEncoder(categories=[['Basic', 'Extended', 'Premium']])\n",
    "ordinal_df['coverage'] = enc.fit_transform(ordinal_df[['coverage']])\n",
    "\n",
    "# For 'education' column\n",
    "enc = OrdinalEncoder(categories=[['High School or Below', 'Bachelor', 'College', 'Master', 'Doctor']])\n",
    "ordinal_df['education'] = enc.fit_transform(ordinal_df[['education']])\n",
    "\n",
    "# For 'vehicle_size' column\n",
    "enc = OrdinalEncoder(categories=[['Small', 'Medsize', 'Large']])\n",
    "ordinal_df['vehicle_size'] = enc.fit_transform(ordinal_df[['vehicle_size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05c79eb-3194-429e-bd68-fdb0a85fbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the two categorical Dataframes\n",
    "\n",
    "result_categorical_df = pd.concat([ordinal_df, con_norminals_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4319b9-7ea2-45f9-ae5f-572abd176290",
   "metadata": {},
   "source": [
    "## Numberical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738728ae-9370-47a2-8d78-dd7b4586aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAN and duplicates\n",
    "numericals_df = numericals_df.dropna()\n",
    "numericals_df = numericals_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094369b-61bb-468d-82f2-8143d2a31733",
   "metadata": {},
   "source": [
    "## Concat both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab78a260-0ce3-46e0-8a4a-c22c9edead27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([result_categorical_df, numericals_df], axis=1)\n",
    "final_df = final_df.drop(columns=['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d7da294-2e0f-4414-9cb8-28b1f83dd86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2303"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop nan of target value\n",
    "\n",
    "final_df['total_claim_amount'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6b8a5f-0a72-4a18-93f0-77edbd864932",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna(subset=['total_claim_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b664bc-1cb6-42c1-9c53-f35c31606b07",
   "metadata": {},
   "source": [
    "## Defining X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc31bd1e-6aa8-466f-aea6-ee02e82d6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns=['total_claim_amount'], axis = 1)\n",
    "y = np.log(final_df['total_claim_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90e23d-6e54-481b-b6b5-e850c23aaeff",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c161fd-78a6-4fc8-8344-7bb8ba282edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state= 42)\n",
    "\n",
    "# X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "# X_test  = pd.DataFrame(X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad36395-7535-47bd-8ccd-c57346b9ba4c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf748fe3-ff13-41bf-8f6c-81d0f9569ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax X_train\n",
    "mm = MinMaxScaler() # Initialize the PowerTransformer\n",
    "mm.fit(X_train) # Fit to and transform X_train\n",
    "X_train=mm.transform(X_train)\n",
    "# MinMax X_test\n",
    "X_test = mm.transform(X_test) # Transform X_test using the fitted transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4956816-0f69-4da6-aa31-ea475827daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PowerTransform y_train\n",
    "pt1 = PowerTransformer()\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train = pt1.fit_transform(y_train)\n",
    "#PowerTransform y_test\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test = pt1.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359d333-83c1-42e3-a240-1baf14183ea4",
   "metadata": {},
   "source": [
    "#### 1. Fit the models LinearRegression,Lasso and Ridge and compare the model performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c53008-7d18-49e7-820e-63b054c88be0",
   "metadata": {},
   "source": [
    "##### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ab6a3d-6e57-4403-80f6-51c63dc7875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: Train -> 0.8428090565406501, Test -> 0.8369025898410395\n"
     ]
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428e209-4bd7-4d6e-abda-494710470e25",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f372de-2273-422d-a4a4-da50791af9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: Train -> 0.8410039929102261, Test -> 0.8387481672923525\n"
     ]
    }
   ],
   "source": [
    "model=Lasso(alpha=0.003)\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab013018-d887-4d2e-baae-2769ebb0e489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00379269019073225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to find the best Alpha\n",
    "\n",
    "def find_best_alpha_lasso(X_train, y_train, X_test, y_test, alphas_lasso):\n",
    "    best_score = -np.inf\n",
    "    best_alpha = None\n",
    "    scores = []\n",
    "    \n",
    "    for alpha in alphas_lasso:\n",
    "        model = Lasso(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        scores.append((alpha, train_score, test_score))\n",
    "        \n",
    "        if test_score > best_score:\n",
    "            best_score = test_score\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    # print(f\"Best Alpha: {best_alpha} with Test Score: {best_score:.4f}\")\n",
    "    return best_alpha\n",
    "# Example usage\n",
    "alphas_lasso = np.logspace(-4, -1, 20)  # Generating 20 values between 10^-4 and 10^-1\n",
    "find_best_alpha_lasso(X_train, y_train, X_test, y_test, alphas_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618ee11-e131-4411-abe2-a775b5dbba26",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9394382-e218-41f8-b73a-204613f31605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: Train -> 0.839808657825552, Test -> 0.8352969393813537\n"
     ]
    }
   ],
   "source": [
    "model=Ridge(alpha=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b652584-cefe-403f-90e8-5e0e0617bf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286427728546842"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function to find the best Alpha\n",
    "\n",
    "def find_best_alpha_ridge(X_train, y_train, X_test, y_test, alphas_ridge):\n",
    "    best_score = -np.inf\n",
    "    best_alpha = None\n",
    "    scores = []\n",
    "    \n",
    "    for alpha in alphas_ridge:\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        scores.append((alpha, train_score, test_score))\n",
    "        \n",
    "        if test_score > best_score:\n",
    "            best_score = test_score\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    # print(f\"Best Alpha: {best_alpha} with Test Score: {best_score:.4f}\")\n",
    "    return best_alpha\n",
    "\n",
    "# Example usage\n",
    "alphas_ridge = np.logspace(-4, 4, 50)  # Generating 50 values between 10^-4 and 10^4\n",
    "find_best_alpha_ridge(X_train, y_train, X_test, y_test, alphas_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db0ae2-6afc-4832-afa6-148c1949c01d",
   "metadata": {},
   "source": [
    "#### 2. Define a function that takes a list of models and trains (and tests) them so we can try a lot of them without repeating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc5b1ad3-87ca-4a3d-a0cd-d9d2eef5fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train, y_train, X_test, y_test, alphas_lasso, alphas_ridge):\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")\n",
    "\n",
    "    best_alpha_lasso = find_best_alpha_lasso(X_train, y_train, X_test, y_test, alphas_lasso)\n",
    "\n",
    "    model=Lasso(alpha=best_alpha_lasso)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")\n",
    "\n",
    "    best_alpha_ridge = find_best_alpha_ridge(X_train, y_train, X_test, y_test, alphas_ridge)\n",
    "\n",
    "    model=Ridge(alpha=best_alpha_ridge)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model.__class__.__name__}: Train -> {model.score(X_train, y_train)}, Test -> {model.score(X_test, y_test)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2cf66bf-5cdd-4a4d-827e-bddccf84a471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: Train -> 0.8428090565406501, Test -> 0.8369025898410395\n",
      "Lasso: Train -> 0.8405400475849193, Test -> 0.8388645351657161\n",
      "Ridge: Train -> 0.8427130262396116, Test -> 0.8370321272242139\n"
     ]
    }
   ],
   "source": [
    "models(X_train, y_train, X_test, y_test, alphas_lasso, alphas_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12da3e99-4fb6-4a20-8d76-3aa669b46ce6",
   "metadata": {},
   "source": [
    "#### 3. Use feature selection techniques (P-Value, RFE) to select a subset of features to train the model with (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce47596f-e001-4a97-8c13-e75ddf6c8ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features based on P-value:\n",
      "Index(['vehicle_size', 'state_Arizona', 'state_California', 'state_Nevada',\n",
      "       'state_Oregon', 'state_Washington', 'response_No', 'response_Yes',\n",
      "       'employmentstatus_Disabled', 'employmentstatus_Employed',\n",
      "       'employmentstatus_Medical Leave', 'employmentstatus_Retired',\n",
      "       'employmentstatus_Unemployed', 'gender_F', 'gender_M',\n",
      "       'location_code_Rural', 'location_code_Suburban', 'location_code_Urban',\n",
      "       'marital_status_Divorced', 'marital_status_Married',\n",
      "       'marital_status_Single', 'policy_type_Corporate Auto',\n",
      "       'policy_type_Personal Auto', 'policy_type_Special Auto',\n",
      "       'sales_channel_Agent', 'sales_channel_Branch',\n",
      "       'sales_channel_Call Center', 'sales_channel_Web', 'policy_Corporate L1',\n",
      "       'policy_Corporate L2', 'policy_Corporate L3', 'policy_Personal L1',\n",
      "       'policy_Personal L2', 'policy_Personal L3', 'policy_Special L1',\n",
      "       'policy_Special L2', 'policy_Special L3', 'vehicle_class_Four-Door Car',\n",
      "       'vehicle_class_Luxury Car', 'vehicle_class_Luxury SUV',\n",
      "       'vehicle_class_SUV', 'vehicle_class_Sports Car',\n",
      "       'vehicle_class_Two-Door Car', 'vehicle_type_A',\n",
      "       'renew_offer_type_Offer1', 'renew_offer_type_Offer2',\n",
      "       'renew_offer_type_Offer3', 'renew_offer_type_Offer4', 'income',\n",
      "       'monthly_premium_auto'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_pvalue(X, y, significance_level=0.05):\n",
    "    # Add a constant term (intercept) to the feature matrix X\n",
    "    X = sm.add_constant(X)\n",
    "    # Fit a linear regression model using Ordinary Least Squares\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    # Extract p-values for each coefficient, excluding the constant term\n",
    "    p_values = model.pvalues[1:]  # Exclude the constant term\n",
    "     # Select features whose p-values are less than the specified significance level\n",
    "    selected_features = X.columns[1:][p_values < significance_level]\n",
    "    # Return the list of selected features\n",
    "    return selected_features\n",
    "# Use case:\n",
    "selected_features_pvalue = feature_selection_pvalue(X, y)\n",
    "# Print or display the selected features\n",
    "print(\"Selected Features based on P-value:\")\n",
    "print(selected_features_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264cee7-b3a5-4c1e-84f1-e2f8dd555bc5",
   "metadata": {},
   "source": [
    "## Variance threshold method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab7831-6e69-4a70-9d7f-d991ba70552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.select_dtypes(include=np.number)\n",
    "X_test  = X_test.select_dtypes(include=np.number)\n",
    "\n",
    "#display(X_train)\n",
    "print(\"Initial number of numerical columns: \",X_train.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "selector = VarianceThreshold() # Default threshold value is 0\n",
    "# Features with a training-set variance lower than this threshold will be removed.\n",
    "selector.fit(X_train)\n",
    "\n",
    "kept_features_indexes = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "kept_features = list(X_train.iloc[:,kept_features_indexes].columns)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_test  = selector.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=kept_features)\n",
    "X_test  = pd.DataFrame(X_test, columns=kept_features)\n",
    "\n",
    "print(\"Final number of numerical columns: \",X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114034e-aecb-47b4-aade-4a5f2828d30b",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87740d02-b2d9-41b9-a447-06d3a4efed24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = final_df.select_dtypes(include = np.number)\n",
    "c = abs(c.corr())\n",
    "#c\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.heatmap(c, annot=True);\n",
    "\n",
    "#c['SalePrice']\n",
    "c_last = c['total_claim_amount'].sort_values(ascending=False)\n",
    "#c_last\n",
    "c_thr = .3\n",
    "cols_to_keep = list(c_last[c_last > c_thr].index)[1:] + [list(c_last[c_last > c_thr].index)[0]]\n",
    "print(cols_to_keep)\n",
    "\n",
    "final_df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3be671-c7b0-4510-8bfd-a5bb3ad0613b",
   "metadata": {},
   "source": [
    "## Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30ce08-6178-4808-9c04-999a2e945070",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = X_train.select_dtypes(include=np.number)\n",
    "X_test  = X_test.select_dtypes(include=np.number)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test  = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "#X_train.isna().sum()\n",
    "nulls = pd.DataFrame(X_train.isna().sum()).reset_index()\n",
    "#nulls.head()\n",
    "nulls.columns = ['Column','nas']\n",
    "#nulls.head()\n",
    "#nulls[nulls['nas'] > 0].head()\n",
    "cols_to_drop = nulls[nulls['nas'] > 0]['Column'] # Too drastic, but made on pourpose for quick filtering (don't do this in production!!)\n",
    "\n",
    "X_train.drop(columns=cols_to_drop, axis=1, inplace = True)\n",
    "X_test.drop(columns=cols_to_drop, axis=1, inplace = True)\n",
    "\n",
    "#display(X_train)\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "selector = RFE(lm, n_features_to_select= 8, step = 1, verbose = 1) #Â Step is how many features to add or drop everytime\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "kept_features = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "kept_features = list(X_train.iloc[:,kept_features].columns)\n",
    "\n",
    "X_train = selector.transform(X_train)\n",
    "X_test  = selector.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=kept_features)\n",
    "X_test  = pd.DataFrame(X_test, columns=kept_features)\n",
    "\n",
    "print(\"Final selected features: \")\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d190808-19a1-4cae-a8d2-237cb09137e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4fb2b-f6be-413a-843f-029504250b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7a8d8-1fc5-4d96-9d7b-c45023f9b963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7f7a6-24c8-4be5-98c9-5d0178284a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad4feda-91dd-417e-acd5-35b8f1e65fbf",
   "metadata": {},
   "source": [
    "#### 4. (optional) Re-fit the models with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5032f-1420-40e8-a8d8-0a80f3fa6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
